# Bank Customer Segmentation üè¶

## Project Overview
A PySpark project built on Databricks that segments bank customers
based on their balance, credit score and savings rate using
real world CSV data.

## Tech Stack
- **Platform:** Databricks
- **Language:** PySpark (Python)
- **File Format:** CSV (input), Delta (output)

## Dataset
Real world style banking dataset with 25 customer records containing
balance, monthly income, monthly expenses, credit score,
number of products and years with bank.

- **Source:** bank_customers.csv
- **Location:** Databricks Volume

## Analysis Performed

### Transformations
| Transformation | Description |
|----------------|-------------|
| customer_segment | Premium / Regular / Basic based on balance |
| savings_rate | Percentage of income saved each month |
| credit_category | Excellent / Good / Fair / Poor based on credit score |

### GroupBy Analysis
- Total customers per segment
- Average balance per segment
- Average credit score per segment
- Average savings rate per segment

### Window Function
- Ranked customers by balance within each customer segment

### Spark SQL
- Average balance and credit score by city
- Ordered by average balance descending

## Output Tables
| Table | Description |
|-------|-------------|
| bank_customer_segments | Cleaned and segmented customer data |
| customer_segment_summary | Aggregated summary by customer segment |

## Key Insights
- Premium customers have significantly higher savings rates
- Excellent credit score customers tend to have higher balances
- Mumbai and Delhi have the highest average customer balances

## How to Run
1. Upload `bank_customers.csv` to your Databricks Volume
2. Open Databricks and create a new notebook
3. Copy the code from `bank_customer_segmentation.py`
4. Update the file path to match your Volume location
5. Run all cells sequentially
6. Check Delta tables in your catalog