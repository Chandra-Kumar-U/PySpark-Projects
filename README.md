# PySpark Projects ðŸš€

## Overview
A collection of PySpark projects built on Databricks covering
the Finance and Banking domain. These projects demonstrate
end-to-end data engineering skills including data ingestion,
transformation, aggregation and loading using PySpark.

## Projects

### 1. Customer Transaction ETL Pipeline
An ETL pipeline that processes raw banking transaction data,
applies business transformations and loads the cleaned data
into a Delta table.
- **Tech:** PySpark, Databricks, Delta
- **Skills:** ETL, StructType, When-Otherwise, Type Casting, Filtering
- **Folder:** customer-transaction-etl-pipeline/

### 2. Loan Default Risk Analysis
Analyzing loan data to identify high risk customers based on
missed payments, loan to income ratio and employment status.
- **Tech:** PySpark, Databricks, Delta
- **Skills:** GroupBy, Aggregations, Window Functions, Spark SQL
- **Folder:** loan-default-risk-analysis/

### 3. Bank Customer Segmentation
Segmenting bank customers based on balance, credit score and
savings rate using real world CSV data.
- **Tech:** PySpark, Databricks, Delta, CSV
- **Skills:** CSV ingestion, Segmentation, GroupBy, Window Functions, Spark SQL
- **Folder:** bank-customer-segmentation/

## Tech Stack
- **Platform:** Databricks
- **Language:** PySpark (Python)
- **Input Formats:** CSV, In-memory DataFrames
- **Output Format:** Delta Tables

## Skills Demonstrated
- Data Ingestion (CSV, createDataFrame)
- Schema Definition (DDL, StructType)
- Data Transformation (withColumn, filter, cast)
- Aggregations (groupBy, sum, avg, count)
- Window Functions (rank, partitionBy)
- Spark SQL (createTempView, SQL queries)
- Data Loading (Delta tables, overwrite mode)

## Author
Chandra Kumar
GitHub: https://github.com/Chandra-Kumar-U